import numpy as np
import pandas as pd
import keras
import keras.backend as K
# from keras.models import
from keras.models import Sequential
from keras.layers import Dense, Conv1D, LSTM, activations,Dropout, SimpleRNN, MaxPooling1D, Flatten
from keras.optimizers import SGD
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error
import math
import matplotlib.pyplot as plt


def create_dateset(dataset, look_back):
    data_x, data_y = [], []
    for i in range(len(dataset)-look_back-1):
        a = dataset[i:(i+look_back), 0]
        data_x.append(a)
        data_y.append(dataset[i+look_back, 0])
    return np.array(data_x), np.array(data_y)

if __name__ == '__main__':
    datafrmae = pd.read_csv('USD_INR.csv', usecols=[1], engine='python', skipfooter=3)
    dataset = datafrmae.values
    dataset = dataset.astype('float32')
    # fix random seed for reproducibility
    # np.random.seed(7)
    # normalize the dataset
    scaler = MinMaxScaler(feature_range=(0, 1))
    dataset = scaler.fit_transform(dataset)

    train_size = int(len(dataset)*0.67)
    test_size = len(dataset) - train_size
    train, test = dataset[0:train_size, :], dataset[train_size: len(dataset), :]
    look_back = 4
    train_x, train_y = create_dateset(train, look_back)
    test_x, test_y = create_dateset(test, look_back)
    # print (train_x[0], train_y[0])
    # print (test_x.shape)
    batch_size = 32

    train_x = train_x.reshape(train_x.shape[0], train_x.shape[1], 1)
    test_x = test_x.reshape(test_x.shape[0], test_x.shape[1], 1)
    # train_y = train_y.reshape(train_y.shape[0], 1,1)
    # test_y = test_y.reshape(test_y.shape[0], 1,1)
    print (train_x.shape)
    print (train_y.shape)
    print (test_x.shape)
    print (test.shape)


    # Convolution  卷积
    kernel_size = 3  # 滤波器长度
    filters_number = 16  # 卷积核个数
    # pool_length = 4  # 池化长度

    # model
    model = Sequential()
    # model.add(Dense(32, activation='relu', input_shape=(None, look_back), name='first_layer'))
    # 1D 卷积层，对词嵌入层输出做卷积操作
    model.add(Conv1D(filters=filters_number,
                     kernel_size=kernel_size,
                     activation='relu',
                     padding='valid',
                     strides=1,
                     input_shape=(look_back, 1)))
    # print (model.output_shape)
    # Conv1D(activation="relu", input_shape=(1, 1), padding="valid", strides=1, filters=16, kernel_size=4)
    # print (model.get_output_sh('first_layer'))

    # 池化层
    model.add(MaxPooling1D(2))
    # model.add(Flatten())
    # LSTM 循环层
    model.add(SimpleRNN(32))
    model.add(Dense(1, activation='sigmoid'))
    model.summary()
    model.compile(loss='mse',
                  optimizer='adam',
                  metrics=['accuracy'])
    model.fit(train_x, train_y, batch_size=batch_size, epochs=10)
    score = model.evaluate(test_x, test_y, batch_size=batch_size)[0]
    print (score)
    # make predictions
    trainPredict = model.predict(train_x)
    testPredict = model.predict(test_x)
    # invert predictions
    trainPredict = scaler.inverse_transform(trainPredict)
    trainY = scaler.inverse_transform([train_y])
    testPredict = scaler.inverse_transform(testPredict)
    testY = scaler.inverse_transform([test_y])
    train_pre = []
    for i in trainPredict:
        train_pre.append(i[0])
    print (train_pre)
    # print ('tainPredict:', trainPredict[0][0])
    print ('train_y:', list(trainY[0]))
    plt.figure()
    x = range(len(trainPredict))
    plt.plot(x, train_pre, 'bs-', label="$train_predictd_data$")
    plt.plot(x, list(trainY[0]), 'ro-', label="$train_data$")
    plt.show()
